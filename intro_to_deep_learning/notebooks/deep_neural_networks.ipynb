{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c0bb87",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/ryanholbrook/deep-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f6a0b",
   "metadata": {},
   "source": [
    "# 1) Input Shape #\n",
    "\n",
    "The target for this task is the column `'CompressiveStrength'`. The remaining columns are the features we'll use as inputs.\n",
    "\n",
    "What would be the input shape for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602d2fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "input_shape = (8,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5907f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2) Define a Model with Hidden Layers #\n",
    "\n",
    "Now create a model with three hidden layers, each having 512 units and the ReLU activation.  Be sure to include an output layer of one unit and no activation, and also `input_shape` as an argument to the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebf50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),    \n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073deea",
   "metadata": {},
   "source": [
    "- feedforward network with three big hidden layers (512 neurons each) to capture complex patterns from the wine features, and a single output for the predicted quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0931c",
   "metadata": {},
   "source": [
    "# 3) Activation Layers #\n",
    "\n",
    "Let's explore activations functions some.\n",
    "\n",
    "The usual way of attaching an activation function to a `Dense` layer is to include it as part of the definition with the `activation` argument. Sometimes though you'll want to put some other layer between the `Dense` layer and its activation function. (We'll see an example of this in Lesson 5 with *batch normalization*.) In this case, we can define the activation in its own `Activation` layer, like so:\n",
    "\n",
    "```\n",
    "layers.Dense(units=8),\n",
    "layers.Activation('relu')\n",
    "```\n",
    "\n",
    "This is completely equivalent to the ordinary way: `layers.Dense(units=8, activation='relu')`.\n",
    "\n",
    "Rewrite the following model so that each activation is in its own `Activation` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE: rewrite this to use activation layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, input_shape=[8]),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(32),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
